{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cats_vs_dogs.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CVyoSqOdjGqn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaANqnUfjL9C","colab_type":"code","outputId":"b482c519-f54e-40d2-b460-6572f44feecf","executionInfo":{"status":"ok","timestamp":1563486941466,"user_tz":240,"elapsed":47439,"user":{"displayName":"jingwei x","photoUrl":"","userId":"12788707513415770799"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# inception model\n","import os\n","from tensorflow.keras import callbacks\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","\n","!wget --no-check-certificate \\\n","  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n","    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","  \n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n","                               include_top = False, \n","                               weights = None)\n","\n","pre_trained_model.load_weights(local_weights_file)\n","\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","  \n","pre_trained_model.summary()\n","\n","#\n","last_layer = pre_trained_model.get_layer('mixed7') # one of the output layers\n","last_output = last_layer.output\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","x = layers.Flatten()(last_output)\n","x = layers.Dense(1024, activation = 'relu')(x)\n","x = layers.Dropout(0.2)(x)\n","x = layers.Dense(1, activation = 'sigmoid')(x)\n","\n","model = Model(pre_trained_model.input, x)\n","model.compile(optimizer = RMSprop(lr = 0.0001), \n","             loss = 'binary_crossentropy', \n","             metrics = ['acc'])\n","\n","model.summary()\n","\n","# call backs\n","class myCallback(callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('val_acc')>0.95):\n","      print(\"\\nReached 95% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()\n","\n","\n","# \n","#import tensorflow as tf\n","#\n","#model = tf.keras.models.Sequential([\n","#    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)), \n","#    tf.keras.layers.MaxPooling2D(2,2), \n","#    tf.keras.layers.Conv2D(32, (3,3), activation='relu'), \n","#    tf.keras.layers.MaxPooling2D(2,2), \n","#    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n","#    tf.keras.layers.MaxPooling2D(2,2), \n","#    tf.keras.layers.Flatten(), \n","#    tf.keras.layers.Dense(512, activation='relu'), \n","#    tf.keras.layers.Dense(1, activation='sigmoid')\n","#])\n","#\n","#\n","#model.summary()\n","#\n","#\n","#from tensorflow.keras.optimizers import RMSprop\n","#\n","#model.compile(loss = 'binary_crossentropy', \n","#             optimizer = RMSprop(lr=0.001), \n","#             metrics = ['acc'])\n","\n","# download\n","\n","!wget --no-check-certificate \\\n","  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n","  -O /tmp/cats_and_dogs_filtered.zip\n","  \n","import os\n","import zipfile\n","\n","local_zip = '/tmp/cats_and_dogs_filtered.zip'\n","\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","\n","zip_ref.extractall('/tmp')\n","zip_ref.close()\n","\n","#\n","base_dir = '/tmp/cats_and_dogs_filtered'\n","\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","\n","# Directory with our training cat/dog pictures\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","\n","# Directory with our validation cat/dog pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","\n","#\n","train_cat_fnames = os.listdir( train_cats_dir )\n","train_dog_fnames = os.listdir( train_dogs_dir )\n","\n","print(train_cat_fnames[:10])\n","print(train_dog_fnames[:10])\n","\n","print('total training cat images :', len(os.listdir( train_cats_dir ) ))\n","print('total training dog images :', len(os.listdir( train_dogs_dir ) ))\n","\n","print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\n","print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))\n","\n","# visualize\n","%matplotlib inline\n","\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","\n","# Parameters for our graph; we'll output images in a 4x4 configuration\n","nrows = 4\n","ncols = 4\n","\n","pic_index = 0 # Index for iterating over images\n","\n","# Set up matplotlib fig, and size it to fit 4x4 pics\n","fig = plt.gcf()\n","fig.set_size_inches(ncols*4, nrows*4)\n","\n","pic_index+=8\n","\n","next_cat_pix = [os.path.join(train_cats_dir, fname) \n","                for fname in train_cat_fnames[ pic_index-8:pic_index] \n","               ]\n","\n","next_dog_pix = [os.path.join(train_dogs_dir, fname) \n","                for fname in train_dog_fnames[ pic_index-8:pic_index]\n","               ]\n","\n","for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n","  # Set up subplot; subplot indices start at 1\n","  sp = plt.subplot(nrows, ncols, i + 1)\n","  sp.axis('Off') # Don't show axes (or gridlines)\n","\n","  img = mpimg.imread(img_path)\n","  plt.imshow(img)\n","\n","plt.show()\n","\n","\n","\n","#\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1.0/255, \n","                                  rotation_range=40, \n","                                  width_shift_range=0.2, \n","                                  height_shift_range=0.2, \n","                                  shear_range=0.2, \n","                                  zoom_range=0.2, \n","                                  horizontal_flip=True, \n","                                  fill_mode='nearest')\n","\n","train_generator = train_datagen.flow_from_directory(\n","  train_dir, \n","  target_size=(150, 150), \n","  batch_size=20, \n","  class_mode='binary') # two classes\n","\n","#\n","test_datagen = ImageDataGenerator(rescale=1.0/255)\n","\n","validation_generator = test_datagen.flow_from_directory(\n","  validation_dir, \n","  target_size=(150, 150), \n","  batch_size = 20, \n","  class_mode = 'binary')\n","\n","\n","\n","\n","# train\n","histroy = model.fit_generator(\n","  train_generator, \n","  steps_per_epoch = 100, \n","  epochs = 15, \n","  validation_data = validation_generator, \n","  validation_steps = 50, \n","    callbacks = [callbacks], \n","  verbose = 2)\n","\n","\n","## run the model\n","import numpy as np\n","\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  path='/content/' + fn\n","  img=image.load_img(path, target_size=(150,150))\n","  \n","  x=image.img_to_array(img)\n","  x=np.expand_dims(x, axis=0)\n","  image=np.vstack([x])\n","  \n","  classes=model.predict(images, batch_size=10)\n","  \n","  print(classes[0])\n","  \n","  if classes[0] > 0:\n","    print(fn+\" is a dog\")\n","  else:\n","    print(fn + \" is a cat\")\n","\n","plt.imshow(img)\n","\n","\n","## visualize intermediate representation\n","import numpy as np\n","import random \n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","\n","#\n","successive_outputs = [layer.output for layer in model.layers[1:]]\n","\n","visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n","\n","# take randome cats/dogs\n","cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n","dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n","\n","img_path = random.choice(cat_img_files + dog_img_files)\n","img = load_img(img_path, target_size = (150, 150))\n","\n","x = img_to_array(img)\n","x = x.reshape((1,) + x.shape)\n","\n","# rescale\n","x /= 255.0\n","\n","successive_feature_maps = visualization_model.predict(x)\n","\n","layer_names = [layer.name for layer in model.layers]\n","\n","#\n","for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n","  if len(feature_map.shape) == 4:\n","    \n","    n_features = feature_map.shape[-1]\n","    size = feature_map.shape[1]\n","    \n","    # tile the images\n","    display_grid = np.zeros((size, size*n_features))\n","    \n","    for i in range(n_features):\n","      x = feature_map[0, :, :, i]\n","      x -= x.mean()\n","      x /= x.std()\n","      x *= 64\n","      x+= 128\n","      x = np.clip(x, 0, 255).astype('uint8')\n","      display_grid[:, i*size:(i+1)*size] = x\n","      \n","# display\n","\n","scale = 20. / n_features\n","plt.figure(figsize=(scale * n_features, scales))\n","plt.title (layer_name)\n","plt.grid(False)\n","plt.imshow(display_grid, aspect='auto', cmap = 'viridis')\n","\n","\n","# accuracy and loss of the model\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc      = history.history[     'acc' ]\n","val_acc  = history.history[ 'val_acc' ]\n","loss     = history.history[    'loss' ]\n","val_loss = history.history['val_loss' ]\n","\n","epochs   = range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     acc )\n","plt.plot  ( epochs, val_acc )\n","plt.title ('Training and validation accuracy')\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     loss )\n","plt.plot  ( epochs, val_loss )\n","plt.title ('Training and validation loss'   )\n","\n","\n","# clean up\n","\n","import os, signal\n","\n","os.kill(     os.getpid() , \n","         signal.SIGKILL\n","       )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","100/100 - 27s - loss: 0.4959 - acc: 0.7660 - val_loss: 0.2695 - val_acc: 0.9180\n","Epoch 2/15\n","\n","Reached 95% accuracy so cancelling training!\n","100/100 - 19s - loss: 0.3778 - acc: 0.8340 - val_loss: 0.2019 - val_acc: 0.9530\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ioTtPgJhIXMs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}